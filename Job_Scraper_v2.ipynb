{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Job_Scraper_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC_Dr0TMoPDz",
        "outputId": "b9a1edc0-1957-4fbc-c12e-f2269d9ff81f"
      },
      "source": [
        "#importing libraries\r\n",
        "!pip install pandasql\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import requests\r\n",
        "from random import random\r\n",
        "from time import sleep\r\n",
        "from collections import namedtuple\r\n",
        "import smtplib\r\n",
        "import csv\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import pandasql as psql\r\n",
        "from pandasql import sqldf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandasql\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/c4/ee4096ffa2eeeca0c749b26f0371bd26aa5c8b611c43de99a4f86d3de0a7/pandasql-0.7.3.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.1.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.3.23)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-cp37-none-any.whl size=26820 sha256=b73053fa08fa25e6a59c3b8a4fbdc2ce767162b8a8c44bb29758b914e2022cde\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/6c/18/b87a2e5fa8a82e9c026311de56210b8d1c01846e18a9607fc9\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY1bEtRuozVF",
        "outputId": "d32901c9-6311-44a6-a6a4-13773b6b6aa4"
      },
      "source": [
        "def generate_url(job_title, job_location):\r\n",
        "    url_template = \"https://in.indeed.com//jobs?q={}&l={}\"\r\n",
        "    url = url_template.format(job_title, job_location)\r\n",
        "    return url\r\n",
        "\r\n",
        "\r\n",
        "def save_record_to_csv(record, filepath, create_new_file=False):\r\n",
        "    \"\"\"Save an individual record to file; set `new_file` flag to `True` to generate new file\"\"\"\r\n",
        "    header = [\"JobTitle\", \"Company\", \"Location\", \"Salary\", \"PostDate\", \"Summary\", \"JobUrl\"]\r\n",
        "    if create_new_file:\r\n",
        "        with open(filepath, mode='w', newline='', encoding='utf-8') as f:\r\n",
        "            writer = csv.writer(f)\r\n",
        "            writer.writerow(header)\r\n",
        "    else:\r\n",
        "        with open(filepath, mode='a+', newline='', encoding='utf-8') as f:\r\n",
        "            writer = csv.writer(f)\r\n",
        "            writer.writerow(record)\r\n",
        "\r\n",
        "def collect_job_cards_from_page(html):\r\n",
        "    soup = BeautifulSoup(html, 'html.parser')\r\n",
        "    cards = soup.find_all('div', 'jobsearch-SerpJobCard')\r\n",
        "    return cards, soup\r\n",
        "\r\n",
        "\r\n",
        "def sleep_for_random_interval():\r\n",
        "    seconds = random() * 10\r\n",
        "    sleep(seconds)\r\n",
        "\r\n",
        "\r\n",
        "def request_jobs_from_indeed(url):\r\n",
        "    headers = {\r\n",
        "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,'\r\n",
        "                  'application/signed-exchange;v=b3;q=0.9',\r\n",
        "        'accept-encoding': 'gzip, deflate, br',\r\n",
        "        'accept-language': 'en-US,en;q=0.9',\r\n",
        "        'cache-control': 'max-age=0',\r\n",
        "        'sec-fetch-dest': 'document',\r\n",
        "        'sec-fetch-mode': 'navigate',\r\n",
        "        'sec-fetch-site': 'none',\r\n",
        "        'sec-fetch-user': '?1',\r\n",
        "        'upgrade-insecure-requests': '1',\r\n",
        "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\r\n",
        "                      'Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47 '\r\n",
        "    }\r\n",
        "    response = requests.get(url, headers=headers)\r\n",
        "    if response.status_code == 200:\r\n",
        "        return response.text\r\n",
        "    else:\r\n",
        "        return None\r\n",
        "\r\n",
        "\r\n",
        "def find_next_page(soup):\r\n",
        "    try:\r\n",
        "        pagination = soup.find(\"a\", {\"aria-label\": \"Next\"}).get(\"href\")\r\n",
        "        return \"https://in.indeed.com/\" + pagination\r\n",
        "    except AttributeError:\r\n",
        "        return None\r\n",
        "\r\n",
        "\r\n",
        "def extract_job_card_data(card):\r\n",
        "    atag = card.h2.a\r\n",
        "    try:\r\n",
        "        job_title = atag.get('title')\r\n",
        "    except AttributeError:\r\n",
        "        job_title = ''\r\n",
        "    try:\r\n",
        "        company = card.find('span', 'company').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        company = ''\r\n",
        "    try:\r\n",
        "        location = card.find('div', 'recJobLoc').get('data-rc-loc')\r\n",
        "    except AttributeError:\r\n",
        "        location = ''\r\n",
        "    try:\r\n",
        "        job_summary = card.find('div', 'summary').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        job_summary = ''\r\n",
        "    try:\r\n",
        "        post_date = card.find('span', 'date').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        post_date = ''\r\n",
        "    try:\r\n",
        "        salary = card.find('span', 'salarytext').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        salary = ''\r\n",
        "    job_url = 'https://in.indeed.com/' + atag.get('href')\r\n",
        "    return job_title, company, location, job_summary, salary, post_date, job_url\r\n",
        "\r\n",
        "\r\n",
        "def main(job_title, job_location, filepath, email=None):\r\n",
        "    unique_jobs = set()  # track job urls to avoid collecting duplicate records\r\n",
        "    total_pages_extract=10\r\n",
        "    print(\"Starting to scrape indeed for `{}` in `{}`\".format(job_title, job_location))\r\n",
        "    url = generate_url(job_title, job_location)\r\n",
        "    save_record_to_csv(None, filepath, create_new_file=True)\r\n",
        "\r\n",
        "    for page in range(0,total_pages_extract):\r\n",
        "      print(url)\r\n",
        "      html = request_jobs_from_indeed(url)\r\n",
        "      if not html:\r\n",
        "        break\r\n",
        "      cards, soup = collect_job_cards_from_page(html)\r\n",
        "      for card in cards:\r\n",
        "        record = extract_job_card_data(card)\r\n",
        "        if not record[-1] in unique_jobs:\r\n",
        "          save_record_to_csv(record, filepath)\r\n",
        "          unique_jobs.add(record[-1])\r\n",
        "      sleep_for_random_interval()\r\n",
        "      url = find_next_page(soup)\r\n",
        "      if not url:\r\n",
        "        break\r\n",
        "      print('Finished collecting {:,d} job postings.'.format(len(unique_jobs)))\r\n",
        "    \r\n",
        "if __name__ == '__main__':\r\n",
        "    # job search settings\r\n",
        "    title = ' '\r\n",
        "    loc = 'India'\r\n",
        "    path = 'raw_data.csv'\r\n",
        "\r\n",
        "\r\n",
        "    # without email settings\r\n",
        "    main(title, loc, path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting to scrape indeed for ` ` in `India`\n",
            "https://in.indeed.com//jobs?q= &l=India\n",
            "Finished collecting 10 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=10\n",
            "Finished collecting 25 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=20\n",
            "Finished collecting 40 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=30\n",
            "Finished collecting 55 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=40\n",
            "Finished collecting 55 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=50\n",
            "Finished collecting 70 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=60\n",
            "Finished collecting 78 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=70\n",
            "Finished collecting 92 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=80\n",
            "Finished collecting 106 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=90\n",
            "Finished collecting 120 job postings.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I13-oJgoqpvs"
      },
      "source": [
        "import pandas as pd\r\n",
        "data=pd.read_csv(\"/content/raw_data.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alCX4Yzmx-n_"
      },
      "source": [
        "data.drop(['PostDate'], axis = 1,inplace=True) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "tBoP3w5ryAai",
        "outputId": "d83db4b0-fd3c-4b58-8220-11fb14a30b46"
      },
      "source": [
        "data.rename(columns = {'Salary':'Summary','Summary':'PostDate'}, inplace = True)\r\n",
        "data.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JobTitle</th>\n",
              "      <th>Company</th>\n",
              "      <th>Location</th>\n",
              "      <th>Summary</th>\n",
              "      <th>PostDate</th>\n",
              "      <th>JobUrl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Security Investigator-All Interested Applicants</td>\n",
              "      <td>Embassy New Delhi</td>\n",
              "      <td>New Delhi, Delhi</td>\n",
              "      <td>Who May Apply/Clarification From the Agency:\\n...</td>\n",
              "      <td>Today</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=17294f0e725dd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Intern/Trainee - Gurgaon 10 C - Agri &amp; Social</td>\n",
              "      <td>PwC</td>\n",
              "      <td>Delhi, Delhi</td>\n",
              "      <td>A career within General Consulting services, w...</td>\n",
              "      <td>6 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=6c58957ae0c39...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Infor BA – Supply Chain</td>\n",
              "      <td>Merinoindia</td>\n",
              "      <td>Remote</td>\n",
              "      <td>Ability to architect solutions by mapping comm...</td>\n",
              "      <td>Just posted</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=33df2f14bfe16...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Office Attendant</td>\n",
              "      <td>RBI</td>\n",
              "      <td>India</td>\n",
              "      <td>RBI Job Notification 2021 - 841 Office Attenda...</td>\n",
              "      <td>5 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=2ac9204a092fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Associate - Gurgaon 10 C - Energy</td>\n",
              "      <td>PwC</td>\n",
              "      <td>Delhi, Delhi</td>\n",
              "      <td>A career in our Government and Public Sector T...</td>\n",
              "      <td>3 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=a98b84eb22efc...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          JobTitle  ...                                             JobUrl\n",
              "0  Security Investigator-All Interested Applicants  ...  https://in.indeed.com//rc/clk?jk=17294f0e725dd...\n",
              "1    Intern/Trainee - Gurgaon 10 C - Agri & Social  ...  https://in.indeed.com//rc/clk?jk=6c58957ae0c39...\n",
              "2                          Infor BA – Supply Chain  ...  https://in.indeed.com//rc/clk?jk=33df2f14bfe16...\n",
              "3                                 Office Attendant  ...  https://in.indeed.com//rc/clk?jk=2ac9204a092fe...\n",
              "4                Associate - Gurgaon 10 C - Energy  ...  https://in.indeed.com//rc/clk?jk=a98b84eb22efc...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uM_lu5FrRF"
      },
      "source": [
        "#Data Transformation\r\n",
        "clean_data=psql.sqldf(\"\"\"  \r\n",
        "select *from data  \r\n",
        "where Location LIKE '%Bengaluru%' \r\n",
        "OR Location LIKE '%Delhi%' \r\n",
        "OR Location LIKE '%New Delhi%' \r\n",
        "OR Location LIKE '%Kolkata%'\r\n",
        "OR Location LIKE '%Chennai%' \r\n",
        "OR Location LIKE '%Hyderabad%' \r\n",
        "OR Location LIKE '%Ahmedabad%' \r\n",
        "OR Location LIKE '%Pune%' \r\n",
        "OR Location LIKE '%Kanpur%' \r\n",
        "OR Location LIKE '%Visakhapatnam%'\r\n",
        "OR Location LIKE '%Surat%' \r\n",
        "OR Location LIKE '%Jaipur%'\r\n",
        "OR Location LIKE '%Nagpur%' \r\n",
        "OR Location LIKE '%Patna%'  \r\n",
        "OR PostDate LIKE '%5 days ago%'\r\n",
        "OR PostDate LIKE '%4 days ago%'\r\n",
        "OR PostDate LIKE '%3 days ago%'\r\n",
        "OR PostDate LIKE '%2 days ago%'\r\n",
        "OR PostDate LIKE '%1 days ago%'\r\n",
        "\"\"\")"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvH6uMsxylbx"
      },
      "source": [
        "\r\n",
        "clean_data.to_csv('/content/sample_data/jobsinindia_cleaned.csv')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqd9cpUu3aVi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}