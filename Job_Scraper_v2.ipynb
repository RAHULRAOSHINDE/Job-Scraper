{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Job_Scraper_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC_Dr0TMoPDz",
        "outputId": "0940731b-50bf-4376-e5a7-bcc92605f71b"
      },
      "source": [
        "#importing libraries\n",
        "!pip install pandasql\n",
        "from bs4 import BeautifulSoup\n",
        "import requests\n",
        "from random import random\n",
        "from time import sleep\n",
        "from collections import namedtuple\n",
        "import smtplib\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pandasql as psql\n",
        "from pandasql import sqldf"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandasql in /usr/local/lib/python3.7/dist-packages (0.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.1.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.3.23)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY1bEtRuozVF",
        "outputId": "1d7e0a9f-b098-452e-b339-b02bea6d1965"
      },
      "source": [
        "#scraping data\n",
        "def generate_url(job_title, job_location):\n",
        "    url_template = \"https://in.indeed.com//jobs?q={}&l={}\"\n",
        "    url = url_template.format(job_title, job_location)\n",
        "    return url\n",
        "\n",
        "\n",
        "def save_record_to_csv(record, filepath, create_new_file=False):\n",
        "    \"\"\"Save an individual record to file; set `new_file` flag to `True` to generate new file\"\"\"\n",
        "    header = [\"JobTitle\", \"Company\", \"Location\", \"Salary\", \"PostDate\", \"Summary\", \"JobUrl\"]\n",
        "    if create_new_file:\n",
        "        with open(filepath, mode='w', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(header)\n",
        "    else:\n",
        "        with open(filepath, mode='a+', newline='', encoding='utf-8') as f:\n",
        "            writer = csv.writer(f)\n",
        "            writer.writerow(record)\n",
        "\n",
        "def collect_job_cards_from_page(html):\n",
        "    soup = BeautifulSoup(html, 'html.parser')\n",
        "    cards = soup.find_all('div', 'jobsearch-SerpJobCard')\n",
        "    return cards, soup\n",
        "\n",
        "\n",
        "def sleep_for_random_interval():\n",
        "    seconds = random() * 10\n",
        "    sleep(seconds)\n",
        "\n",
        "\n",
        "def request_jobs_from_indeed(url):\n",
        "    headers = {\n",
        "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,'\n",
        "                  'application/signed-exchange;v=b3;q=0.9',\n",
        "        'accept-encoding': 'gzip, deflate, br',\n",
        "        'accept-language': 'en-US,en;q=0.9',\n",
        "        'cache-control': 'max-age=0',\n",
        "        'sec-fetch-dest': 'document',\n",
        "        'sec-fetch-mode': 'navigate',\n",
        "        'sec-fetch-site': 'none',\n",
        "        'sec-fetch-user': '?1',\n",
        "        'upgrade-insecure-requests': '1',\n",
        "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "                      'Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47 '\n",
        "    }\n",
        "    response = requests.get(url, headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.text\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "\n",
        "def find_next_page(soup):\n",
        "    try:\n",
        "        pagination = soup.find(\"a\", {\"aria-label\": \"Next\"}).get(\"href\")\n",
        "        return \"https://in.indeed.com/\" + pagination\n",
        "    except AttributeError:\n",
        "        return None\n",
        "\n",
        "\n",
        "def extract_job_card_data(card):\n",
        "    atag = card.h2.a\n",
        "    try:\n",
        "        job_title = atag.get('title')\n",
        "    except AttributeError:\n",
        "        job_title = ''\n",
        "    try:\n",
        "        company = card.find('span', 'company').text.strip()\n",
        "    except AttributeError:\n",
        "        company = ''\n",
        "    try:\n",
        "        location = card.find('div', 'recJobLoc').get('data-rc-loc')\n",
        "    except AttributeError:\n",
        "        location = ''\n",
        "    try:\n",
        "        job_summary = card.find('div', 'summary').text.strip()\n",
        "    except AttributeError:\n",
        "        job_summary = ''\n",
        "    try:\n",
        "        post_date = card.find('span', 'date').text.strip()\n",
        "    except AttributeError:\n",
        "        post_date = ''\n",
        "    try:\n",
        "        salary = card.find('span', 'salarytext').text.strip()\n",
        "    except AttributeError:\n",
        "        salary = ''\n",
        "    job_url = 'https://in.indeed.com/' + atag.get('href')\n",
        "    return job_title, company, location, job_summary, salary, post_date, job_url\n",
        "\n",
        "\n",
        "def main(job_title, job_location, filepath, email=None):\n",
        "    unique_jobs = set()  # track job urls to avoid collecting duplicate records\n",
        "    total_pages_extract=15\n",
        "    print(\"Starting to scrape indeed for `{}` in `{}`\".format(job_title, job_location))\n",
        "    url = generate_url(job_title, job_location)\n",
        "    save_record_to_csv(None, filepath, create_new_file=True)\n",
        "\n",
        "    for page in range(0,total_pages_extract):\n",
        "      print(url)\n",
        "      html = request_jobs_from_indeed(url)\n",
        "      if not html:\n",
        "        break\n",
        "      cards, soup = collect_job_cards_from_page(html)\n",
        "      for card in cards:\n",
        "        record = extract_job_card_data(card)\n",
        "        if not record[-1] in unique_jobs:\n",
        "          save_record_to_csv(record, filepath)\n",
        "          unique_jobs.add(record[-1])\n",
        "      sleep_for_random_interval()\n",
        "      url = find_next_page(soup)\n",
        "      if not url:\n",
        "        break\n",
        "      print('Finished collecting {:,d} job postings.'.format(len(unique_jobs)))\n",
        "    \n",
        "if __name__ == '__main__':\n",
        "    # job search settings\n",
        "    title = ' '\n",
        "    loc = 'India'\n",
        "    path = 'raw_data.csv'\n",
        "\n",
        "\n",
        "    # without email settings\n",
        "    main(title, loc, path)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting to scrape indeed for ` ` in `India`\n",
            "https://in.indeed.com//jobs?q= &l=India\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I13-oJgoqpvs"
      },
      "source": [
        "#reading raw data\n",
        "import pandas as pd\n",
        "data=pd.read_csv(\"/content/raw_data.csv\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alCX4Yzmx-n_"
      },
      "source": [
        "data.drop(['PostDate'], axis = 1,inplace=True) "
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBoP3w5ryAai"
      },
      "source": [
        "data.rename(columns = {'Salary':'Description','Summary':'PostDate'}, inplace = True)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uM_lu5FrRF"
      },
      "source": [
        "#Data Transformation\n",
        "jobsinindia=psql.sqldf(\"\"\"  \n",
        "select *from data  \n",
        "where Location LIKE 'Bengaluru%' \n",
        "OR Location LIKE 'Delhi%' \n",
        "OR Location LIKE 'New Delhi%' \n",
        "OR Location LIKE 'Kolkata%'\n",
        "OR Location LIKE 'Chennai%' \n",
        "OR Location LIKE 'Hyderabad%' \n",
        "OR Location LIKE 'Ahmedabad%' \n",
        "OR Location LIKE 'Pune%' \n",
        "OR Location LIKE 'Kanpur%' \n",
        "OR Location LIKE 'Visakhapatnam%'\n",
        "OR Location LIKE 'Surat%' \n",
        "OR Location LIKE 'Jaipur%'\n",
        "OR Location LIKE 'Nagpur%' \n",
        "OR Location LIKE 'Patna%'  \n",
        "\"\"\")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "iKBqSkpCi4Wp",
        "outputId": "5b5fe750-f0fd-4f81-b257-1d2f18ded84f"
      },
      "source": [
        "recently_posted=psql.sqldf(\"\"\"\n",
        "select *from jobsinindia\n",
        "where PostDate LIKE '1 days ago%' OR \n",
        "PostDate  LIKE '2 days ago%' OR \n",
        "PostDate  LIKE '3 days ago%' OR \n",
        "PostDate  LIKE '4 days ago%' OR \n",
        "PostDate  LIKE '5 days ago%'\n",
        "\"\"\")\n",
        "\n",
        "recently_posted.head(5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JobTitle</th>\n",
              "      <th>Company</th>\n",
              "      <th>Location</th>\n",
              "      <th>Description</th>\n",
              "      <th>PostDate</th>\n",
              "      <th>JobUrl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [JobTitle, Company, Location, Description, PostDate, JobUrl]\n",
              "Index: []"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvH6uMsxylbx"
      },
      "source": [
        "recently_posted.to_csv('/content/sample_data/jobsinindia.csv')"
      ],
      "execution_count": 43,
      "outputs": []
    }
  ]
}