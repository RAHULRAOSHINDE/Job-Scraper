{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Job_Scraper_v2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aC_Dr0TMoPDz",
        "outputId": "a6b810b3-04b8-4c75-c207-cc003c00785a"
      },
      "source": [
        "#importing libraries\r\n",
        "!pip install pandasql\r\n",
        "from bs4 import BeautifulSoup\r\n",
        "import requests\r\n",
        "from random import random\r\n",
        "from time import sleep\r\n",
        "from collections import namedtuple\r\n",
        "import smtplib\r\n",
        "import csv\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import pandasql as psql\r\n",
        "from pandasql import sqldf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandasql\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/c4/ee4096ffa2eeeca0c749b26f0371bd26aa5c8b611c43de99a4f86d3de0a7/pandasql-0.7.3.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.1.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.3.23)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-cp37-none-any.whl size=26820 sha256=a72b45b41c9cf4d45db3946b585d74f063255786e0ac332ed70c8494247d8551\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/6c/18/b87a2e5fa8a82e9c026311de56210b8d1c01846e18a9607fc9\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY1bEtRuozVF",
        "outputId": "c151d3b9-5760-45b4-bfb9-2e2c1507d621"
      },
      "source": [
        "#scraping data\r\n",
        "def generate_url(job_title, job_location):\r\n",
        "    url_template = \"https://in.indeed.com//jobs?q={}&l={}\"\r\n",
        "    url = url_template.format(job_title, job_location)\r\n",
        "    return url\r\n",
        "\r\n",
        "\r\n",
        "def save_record_to_csv(record, filepath, create_new_file=False):\r\n",
        "    \"\"\"Save an individual record to file; set `new_file` flag to `True` to generate new file\"\"\"\r\n",
        "    header = [\"JobTitle\", \"Company\", \"Location\", \"Salary\", \"PostDate\", \"Summary\", \"JobUrl\"]\r\n",
        "    if create_new_file:\r\n",
        "        with open(filepath, mode='w', newline='', encoding='utf-8') as f:\r\n",
        "            writer = csv.writer(f)\r\n",
        "            writer.writerow(header)\r\n",
        "    else:\r\n",
        "        with open(filepath, mode='a+', newline='', encoding='utf-8') as f:\r\n",
        "            writer = csv.writer(f)\r\n",
        "            writer.writerow(record)\r\n",
        "\r\n",
        "def collect_job_cards_from_page(html):\r\n",
        "    soup = BeautifulSoup(html, 'html.parser')\r\n",
        "    cards = soup.find_all('div', 'jobsearch-SerpJobCard')\r\n",
        "    return cards, soup\r\n",
        "\r\n",
        "\r\n",
        "def sleep_for_random_interval():\r\n",
        "    seconds = random() * 10\r\n",
        "    sleep(seconds)\r\n",
        "\r\n",
        "\r\n",
        "def request_jobs_from_indeed(url):\r\n",
        "    headers = {\r\n",
        "        'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,'\r\n",
        "                  'application/signed-exchange;v=b3;q=0.9',\r\n",
        "        'accept-encoding': 'gzip, deflate, br',\r\n",
        "        'accept-language': 'en-US,en;q=0.9',\r\n",
        "        'cache-control': 'max-age=0',\r\n",
        "        'sec-fetch-dest': 'document',\r\n",
        "        'sec-fetch-mode': 'navigate',\r\n",
        "        'sec-fetch-site': 'none',\r\n",
        "        'sec-fetch-user': '?1',\r\n",
        "        'upgrade-insecure-requests': '1',\r\n",
        "        'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\r\n",
        "                      'Chrome/87.0.4280.67 Safari/537.36 Edg/87.0.664.47 '\r\n",
        "    }\r\n",
        "    response = requests.get(url, headers=headers)\r\n",
        "    if response.status_code == 200:\r\n",
        "        return response.text\r\n",
        "    else:\r\n",
        "        return None\r\n",
        "\r\n",
        "\r\n",
        "def find_next_page(soup):\r\n",
        "    try:\r\n",
        "        pagination = soup.find(\"a\", {\"aria-label\": \"Next\"}).get(\"href\")\r\n",
        "        return \"https://in.indeed.com/\" + pagination\r\n",
        "    except AttributeError:\r\n",
        "        return None\r\n",
        "\r\n",
        "\r\n",
        "def extract_job_card_data(card):\r\n",
        "    atag = card.h2.a\r\n",
        "    try:\r\n",
        "        job_title = atag.get('title')\r\n",
        "    except AttributeError:\r\n",
        "        job_title = ''\r\n",
        "    try:\r\n",
        "        company = card.find('span', 'company').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        company = ''\r\n",
        "    try:\r\n",
        "        location = card.find('div', 'recJobLoc').get('data-rc-loc')\r\n",
        "    except AttributeError:\r\n",
        "        location = ''\r\n",
        "    try:\r\n",
        "        job_summary = card.find('div', 'summary').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        job_summary = ''\r\n",
        "    try:\r\n",
        "        post_date = card.find('span', 'date').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        post_date = ''\r\n",
        "    try:\r\n",
        "        salary = card.find('span', 'salarytext').text.strip()\r\n",
        "    except AttributeError:\r\n",
        "        salary = ''\r\n",
        "    job_url = 'https://in.indeed.com/' + atag.get('href')\r\n",
        "    return job_title, company, location, job_summary, salary, post_date, job_url\r\n",
        "\r\n",
        "\r\n",
        "def main(job_title, job_location, filepath, email=None):\r\n",
        "    unique_jobs = set()  # track job urls to avoid collecting duplicate records\r\n",
        "    total_pages_extract=15\r\n",
        "    print(\"Starting to scrape indeed for `{}` in `{}`\".format(job_title, job_location))\r\n",
        "    url = generate_url(job_title, job_location)\r\n",
        "    save_record_to_csv(None, filepath, create_new_file=True)\r\n",
        "\r\n",
        "    for page in range(0,total_pages_extract):\r\n",
        "      print(url)\r\n",
        "      html = request_jobs_from_indeed(url)\r\n",
        "      if not html:\r\n",
        "        break\r\n",
        "      cards, soup = collect_job_cards_from_page(html)\r\n",
        "      for card in cards:\r\n",
        "        record = extract_job_card_data(card)\r\n",
        "        if not record[-1] in unique_jobs:\r\n",
        "          save_record_to_csv(record, filepath)\r\n",
        "          unique_jobs.add(record[-1])\r\n",
        "      sleep_for_random_interval()\r\n",
        "      url = find_next_page(soup)\r\n",
        "      if not url:\r\n",
        "        break\r\n",
        "      print('Finished collecting {:,d} job postings.'.format(len(unique_jobs)))\r\n",
        "    \r\n",
        "if __name__ == '__main__':\r\n",
        "    # job search settings\r\n",
        "    title = ' '\r\n",
        "    loc = 'India'\r\n",
        "    path = 'raw_data.csv'\r\n",
        "\r\n",
        "\r\n",
        "    # without email settings\r\n",
        "    main(title, loc, path)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Starting to scrape indeed for ` ` in `India`\n",
            "https://in.indeed.com//jobs?q= &l=India\n",
            "Finished collecting 15 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=10\n",
            "Finished collecting 30 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=20\n",
            "Finished collecting 40 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=30\n",
            "Finished collecting 55 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=40\n",
            "Finished collecting 58 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=50\n",
            "Finished collecting 71 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=60\n",
            "Finished collecting 78 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=70\n",
            "Finished collecting 91 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=80\n",
            "Finished collecting 106 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=90\n",
            "Finished collecting 118 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=100\n",
            "Finished collecting 131 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=110\n",
            "Finished collecting 145 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=120\n",
            "Finished collecting 156 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=130\n",
            "Finished collecting 168 job postings.\n",
            "https://in.indeed.com//jobs?q=+&l=India&start=140\n",
            "Finished collecting 177 job postings.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I13-oJgoqpvs"
      },
      "source": [
        "#reading raw data\r\n",
        "import pandas as pd\r\n",
        "data=pd.read_csv(\"/content/raw_data.csv\")"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alCX4Yzmx-n_"
      },
      "source": [
        "data.drop(['PostDate'], axis = 1,inplace=True) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBoP3w5ryAai"
      },
      "source": [
        "data.rename(columns = {'Salary':'Summary','Summary':'PostDate'}, inplace = True)"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4uM_lu5FrRF"
      },
      "source": [
        "#Data Transformation\r\n",
        "jobsinindia=psql.sqldf(\"\"\"  \r\n",
        "select *from data  \r\n",
        "where Location LIKE 'Bengaluru%' \r\n",
        "OR Location LIKE 'Delhi%' \r\n",
        "OR Location LIKE 'New Delhi%' \r\n",
        "OR Location LIKE 'Kolkata%'\r\n",
        "OR Location LIKE 'Chennai%' \r\n",
        "OR Location LIKE 'Hyderabad%' \r\n",
        "OR Location LIKE 'Ahmedabad%' \r\n",
        "OR Location LIKE 'Pune%' \r\n",
        "OR Location LIKE 'Kanpur%' \r\n",
        "OR Location LIKE 'Visakhapatnam%'\r\n",
        "OR Location LIKE 'Surat%' \r\n",
        "OR Location LIKE 'Jaipur%'\r\n",
        "OR Location LIKE 'Nagpur%' \r\n",
        "OR Location LIKE 'Patna%'  \r\n",
        "\"\"\")"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "iKBqSkpCi4Wp",
        "outputId": "3e6365a0-73d8-48a6-afdd-2b550c09fa95"
      },
      "source": [
        "recently_posted=psql.sqldf(\"\"\"\r\n",
        "select *from jobsinindia\r\n",
        "where PostDate LIKE '1 days ago%' OR \r\n",
        "PostDate  LIKE '2 days ago%' OR \r\n",
        "PostDate  LIKE '3 days ago%' OR \r\n",
        "PostDate  LIKE '4 days ago%' OR \r\n",
        "PostDate  LIKE '5 days ago%'\r\n",
        "\"\"\")\r\n",
        "\r\n",
        "recently_posted.head(5)"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>JobTitle</th>\n",
              "      <th>Company</th>\n",
              "      <th>Location</th>\n",
              "      <th>Summary</th>\n",
              "      <th>PostDate</th>\n",
              "      <th>JobUrl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Administrative Business Partner</td>\n",
              "      <td>Google</td>\n",
              "      <td>Bengaluru, Karnataka</td>\n",
              "      <td>Due to the current health crisis related to CO...</td>\n",
              "      <td>4 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=70023c86205af...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Associate - Gurgaon 10 C - Energy</td>\n",
              "      <td>PwC</td>\n",
              "      <td>Delhi, Delhi</td>\n",
              "      <td>A career in our Government and Public Sector T...</td>\n",
              "      <td>3 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=a98b84eb22efc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Clerk And Computer Operator</td>\n",
              "      <td>SHREE GANESH MEDICOS</td>\n",
              "      <td>Delhi, Delhi</td>\n",
              "      <td>COMPUTER OPERATOR FOR PHARMACY STORE IN DELHI ...</td>\n",
              "      <td>3 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=592301b7dada6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Event Coordinator</td>\n",
              "      <td>Walmart Global Technology Services</td>\n",
              "      <td>Bengaluru, Karnataka</td>\n",
              "      <td>Conducting short- and long-term planning and m...</td>\n",
              "      <td>5 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=7079e6aa8efa6...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Coordination Responsible Production</td>\n",
              "      <td>Tetra Pak</td>\n",
              "      <td>Pune, Maharashtra</td>\n",
              "      <td>At Tetra Pak we touch millions of lives every ...</td>\n",
              "      <td>5 days ago</td>\n",
              "      <td>https://in.indeed.com//rc/clk?jk=b5d9df8881da6...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                              JobTitle  ...                                             JobUrl\n",
              "0      Administrative Business Partner  ...  https://in.indeed.com//rc/clk?jk=70023c86205af...\n",
              "1    Associate - Gurgaon 10 C - Energy  ...  https://in.indeed.com//rc/clk?jk=a98b84eb22efc...\n",
              "2          Clerk And Computer Operator  ...  https://in.indeed.com//rc/clk?jk=592301b7dada6...\n",
              "3                    Event Coordinator  ...  https://in.indeed.com//rc/clk?jk=7079e6aa8efa6...\n",
              "4  Coordination Responsible Production  ...  https://in.indeed.com//rc/clk?jk=b5d9df8881da6...\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvH6uMsxylbx"
      },
      "source": [
        "recently_posted.to_csv('/content/sample_data/jobsinindia.csv')"
      ],
      "execution_count": 120,
      "outputs": []
    }
  ]
}